#!/usr/bin/env python

from Coach import Coach
from utils import *
import numpy
import GA
import os
import json
import tarfile

prefix = '/opt/ml/'

input_path = prefix + 'input/data'
output_path = os.path.join(prefix, 'output')
model_path = os.path.join(prefix, 'model')
param_path = os.path.join(prefix, 'input/config/hyperparameters.json')

# Read in any hyperparameters that the user passed with the training job
with open(param_path, 'r') as tc:
    args = dotdict(json.load(tc))

if args['game'] == 'tictactoe':
    from games.tictactoe.TicTacToeGame import TicTacToeGame as Game
    from games.tictactoe.mxnet.NNet import NNetWrapper as nn
if args['game'] == 'othello':
    from games.othello.OthelloGame import OthelloGame as Game
    from games.othello.mxnet.NNet import NNetWrapper as nn

args['input_path'] = str(input_path)+'/train'
args['cuda'] = True
args['numIters'] = int(args['numIters'])
args['numEps'] = int(args['numEps'])
args['tempThreshold'] = int(args['tempThreshold'])
args['updateThreshold'] = float(args['updateThreshold'])
args['maxlenOfQueue'] = int(args['maxlenOfQueue'])
args['numMCTSSims'] = int(args['numMCTSSims'])
args['arenaCompare'] = int(args['arenaCompare'])
args['cpuct'] = int(args['cpuct'])
args['load_model'] = args['load_model'].lower() == 'true'
args['load_examples'] = args['load_examples'].lower() == 'true'
args['numItersForTrainExamplesHistory'] = int(args['numItersForTrainExamplesHistory'])
args['lr'] = float(args['lr'])
args['dropout'] = float(args['dropout'])
args['epochs'] = int(args['epochs'])
args['batch_size'] = int(args['batch_size'])

print(os.listdir(args['input_path']))

if args['load_model'] or args['load_examples']:
    tar = tarfile.open(args['input_path']+'/model.tar.gz', "r:gz")
    tar.extractall()
    tar.close()

def train():
    """
    Genetic algorithm parameters:
        Mating pool size
        Population size
    """
    sol_per_pop = int(args['sol_per_pop'])
    num_parents = int(args['num_parents'])
    num_generations = int(args['num_generations'])
    alpha_index = 0

    # Creating the environment.
    game = Game()
    master = Coach(game, args)


    # Creating the initial population.
    new_population = numpy.array([nn(game, args) for i in range(0,sol_per_pop)])

    if args['load_model']:
        for i,p in enumerate(new_population):
            p.load_checkpoint(args['input_path'], 'padawan{}.network'.format(i))
    if args['load_examples']:
        master.loadTrainExamples('{}/train.examples'.format(args['input_path']))

    """
    Start Genetic Algorithm
    """
    ancestors = list(range(0,sol_per_pop))
    for generation in range(num_generations):
        # Generate Train Examples by using alpha chromosome
        alpha_padawan = new_population[alpha_index] # Select Alpha Padawan, usually is the first in list.
        train_examples = master.generate(alpha_padawan)

        # Training each chromosome in the population osing Train Examples.
        master.train(new_population, train_examples)

        # Measing the fitness of each chromosome in the population.
        fitness = GA.cal_pop_fitness(new_population, args)

        # Selecting the best parents in the population for mating.
        parents, indices = GA.select_mating_pool(new_population, fitness, num_parents)

        # Generating next generation using crossover.
        offspring_crossover = GA.crossover(parents, sol_per_pop-num_parents, nn, args)

        # Adding some variations to the offsrping using mutation.
        offspring_mutation = GA.mutation(offspring_crossover)

        # Creating the new population based on the parents and offspring.
        new_population[0:num_parents] = parents
        new_population[num_parents:] = offspring_mutation

        # Save Current State
        print("Save Checkpoint")
        GA.save(new_population, model_path)
        print("Save Train Examples")
        master.saveTrainExamples(output_path, train_examples_file_name)

        # Print current results
        lossness = [min(p.get_loss()) for p in parents]
        ancestors = [indices.index(i) for i in set(ancestors).intersection(indices)]
        print("Generation : {} | Best result : {} | Ancestors {}".format(generation, min(lossness).asscalar(), ancestors) )
        print('>Alpha Padawan ', parents[0].name)
        for m in parents[1:]:
            print('Senior Padawan ', m.name)
        for m in offspring_mutation:
            print('Junior Padawan ', m.name)
        if (len(ancestors) == 0):
            print("All ancestors are dead, generating..")
            ancestors = list(range(0,num_parents))
        alpha_index = 0

    # Getting the best solution after iterating finishing all generations.
    #At first, the fitness is calculated for each solution in the final generation.
    fitness = GA.cal_pop_fitness(new_population, args)
    # Then return the index of that solution corresponding to the best fitness.
    best_match_idx = numpy.where(fitness == numpy.max(fitness))

    print("Best solution : ", new_population[best_match_idx])
    print("Best solution fitness : ", fitness[best_match_idx])

if __name__ == '__main__':
    train()
